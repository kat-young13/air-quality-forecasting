{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bme_file_location = \"sofia/*bme280sof.csv\"\n",
    "sds_file_location = \"sofia/*sds011sof.csv\"\n",
    "\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "df_bme = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", infer_schema) \\\n",
    "    .option(\"header\", first_row_is_header) \\\n",
    "    .option(\"sep\", delimiter) \\\n",
    "    .load(bme_file_location)\n",
    "\n",
    "df_sds = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", infer_schema) \\\n",
    "    .option(\"header\", first_row_is_header) \\\n",
    "    .option(\"sep\", delimiter) \\\n",
    "    .load(sds_file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|        ts|           avg(P1)|           avg(P2)|\n",
      "+----------+------------------+------------------+\n",
      "|2017-07-01|17.764459663706905| 8.341274009698298|\n",
      "|2017-07-02| 9.846284524930946| 6.325375406399083|\n",
      "|2017-07-03| 20.35557791635185|17.195223293020778|\n",
      "|2017-07-04| 8.984114511906204| 6.868896334621589|\n",
      "|2017-07-05|10.412705222705204| 7.964031059031034|\n",
      "|2017-07-06| 10.85810864999049| 8.447780535930221|\n",
      "|2017-07-07| 9.614079073024804| 7.430200547526521|\n",
      "|2017-07-08| 12.10184730986929| 9.885236809576535|\n",
      "|2017-07-09|12.441132935466957|10.319859653725107|\n",
      "|2017-07-10|14.278580865387667|12.425794746989531|\n",
      "|2017-07-11|16.458481004748865|13.907630592351836|\n",
      "|2017-07-12|14.077904752827688|10.800456856017346|\n",
      "|2017-07-13| 11.50965046888325| 8.878007956805918|\n",
      "|2017-07-14| 5.461827450735781|  3.10989585931652|\n",
      "|2017-07-15|10.245437171815821| 7.799760959824183|\n",
      "|2017-07-16|11.484685678666041|  9.46174505220515|\n",
      "|2017-07-17| 8.730244358596998|  7.05922492028453|\n",
      "|2017-07-18|11.758467153284702| 9.619662928016169|\n",
      "|2017-07-19|10.757269963337261| 8.447159080747532|\n",
      "|2017-07-20|10.377995553018224| 8.262260148432995|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import to_timestamp,date_format\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import count, avg\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "df_sds_transformed = df_sds.withColumn('year',year(df_sds.timestamp))\\\n",
    "    .withColumn('month', month(df_sds.timestamp))\\\n",
    "    .withColumn(\"day\", date_format(col(\"timestamp\"), \"d\"))\\\n",
    "    .withColumn(\"ts\", to_date(col(\"timestamp\")).cast(\"date\"))\n",
    "\n",
    "df_sds_transformed = df_sds_transformed.groupBy(\"ts\").agg(avg(\"P1\"), avg(\"P2\")).orderBy([\"ts\"], ascending=True)\n",
    "\n",
    "df_sds_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|  avg(temperature)|     avg(humidity)|\n",
      "+----------+-----------------+------------------+------------------+\n",
      "|2017-07-01|94572.18985080464| 33.33327613327619|32.792403355736745|\n",
      "|2017-07-02|94441.42854684066|28.197254514672572| 44.52180304740427|\n",
      "|2017-07-03|94668.76243252479| 18.25461707200767| 78.17694325226547|\n",
      "|2017-07-04|95313.96683276288| 22.32803235375923|  50.4074079911003|\n",
      "|2017-07-05|95440.82530922632|23.534423652694652|44.841247660928104|\n",
      "|2017-07-06|95312.02019876736|25.778363851992424| 42.49701185958226|\n",
      "|2017-07-07|95248.96706425186|27.469182004089852|40.482749797878675|\n",
      "|2017-07-08|95059.96317789162|  25.7144688644688| 51.47889969005336|\n",
      "|2017-07-09|95089.78527820377|27.075451422027033| 49.46747614048477|\n",
      "|2017-07-10| 95128.1010232264|28.758966410703227|44.910974230932034|\n",
      "|2017-07-11|95059.89666140139|30.580405242122854| 41.59478715493988|\n",
      "|2017-07-12|94791.26359009359| 30.41663144117502| 36.67443695768059|\n",
      "|2017-07-13| 94660.5128211271|28.239342143762816|  40.2070233102511|\n",
      "|2017-07-14|94698.49576498086|25.985152705061278| 35.94933100639909|\n",
      "|2017-07-15|94722.05143758388|23.879997175673175| 48.98377471286015|\n",
      "|2017-07-16|95101.30591753831|17.941519693602615| 71.34576150172559|\n",
      "|2017-07-17|95316.44255811958|18.957777725805787| 65.99736470368151|\n",
      "|2017-07-18|95171.17375061983|22.368150564730172| 55.49259010934609|\n",
      "|2017-07-19|94549.30462410931|24.076660417047684| 47.53020578013586|\n",
      "|2017-07-20|94961.17755593521| 25.72600174937875| 43.76265629315902|\n",
      "+----------+-----------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bme_transformed = df_bme.withColumn('year',year(df_bme.timestamp))\\\n",
    "    .withColumn('month', month(df_bme.timestamp))\\\n",
    "    .withColumn(\"day\", date_format(col(\"timestamp\"), \"d\"))\\\n",
    "    .withColumn(\"ts\", to_date(col(\"timestamp\")).cast(\"date\"))\n",
    "\n",
    "df_bme_transformed = df_bme_transformed.groupBy(\"ts\").agg(avg(\"pressure\"), avg(\"temperature\"), avg(\"humidity\"))\\\n",
    "    .orderBy([\"ts\"], ascending=True)\n",
    "\n",
    "df_bme_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|  avg(temperature)|     avg(humidity)|           avg(P1)|           avg(P2)|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|2017-07-01|94572.18985080464| 33.33327613327619|32.792403355736745|17.764459663706905| 8.341274009698298|\n",
      "|2017-07-02|94441.42854684066|28.197254514672572| 44.52180304740427| 9.846284524930946| 6.325375406399083|\n",
      "|2017-07-03|94668.76243252479| 18.25461707200767| 78.17694325226547| 20.35557791635185|17.195223293020778|\n",
      "|2017-07-04|95313.96683276288| 22.32803235375923|  50.4074079911003| 8.984114511906204| 6.868896334621589|\n",
      "|2017-07-05|95440.82530922632|23.534423652694652|44.841247660928104|10.412705222705204| 7.964031059031034|\n",
      "|2017-07-06|95312.02019876736|25.778363851992424| 42.49701185958226| 10.85810864999049| 8.447780535930221|\n",
      "|2017-07-07|95248.96706425186|27.469182004089852|40.482749797878675| 9.614079073024804| 7.430200547526521|\n",
      "|2017-07-08|95059.96317789162|  25.7144688644688| 51.47889969005336| 12.10184730986929| 9.885236809576535|\n",
      "|2017-07-09|95089.78527820377|27.075451422027033| 49.46747614048477|12.441132935466957|10.319859653725107|\n",
      "|2017-07-10| 95128.1010232264|28.758966410703227|44.910974230932034|14.278580865387667|12.425794746989531|\n",
      "|2017-07-11|95059.89666140139|30.580405242122854| 41.59478715493988|16.458481004748865|13.907630592351836|\n",
      "|2017-07-12|94791.26359009359| 30.41663144117502| 36.67443695768059|14.077904752827688|10.800456856017346|\n",
      "|2017-07-13| 94660.5128211271|28.239342143762816|  40.2070233102511| 11.50965046888325| 8.878007956805918|\n",
      "|2017-07-14|94698.49576498086|25.985152705061278| 35.94933100639909| 5.461827450735781|  3.10989585931652|\n",
      "|2017-07-15|94722.05143758388|23.879997175673175| 48.98377471286015|10.245437171815821| 7.799760959824183|\n",
      "|2017-07-16|95101.30591753831|17.941519693602615| 71.34576150172559|11.484685678666041|  9.46174505220515|\n",
      "|2017-07-17|95316.44255811958|18.957777725805787| 65.99736470368151| 8.730244358596998|  7.05922492028453|\n",
      "|2017-07-18|95171.17375061983|22.368150564730172| 55.49259010934609|11.758467153284702| 9.619662928016169|\n",
      "|2017-07-19|94549.30462410931|24.076660417047684| 47.53020578013586|10.757269963337261| 8.447159080747532|\n",
      "|2017-07-20|94961.17755593521| 25.72600174937875| 43.76265629315902|10.377995553018224| 8.262260148432995|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|  avg(temperature)|     avg(humidity)|           avg(P1)|           avg(P2)|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|2017-07-01|94572.18985080464| 33.33327613327619|32.792403355736745|17.764459663706905| 8.341274009698298|\n",
      "|2017-07-02|94441.42854684066|28.197254514672572| 44.52180304740427| 9.846284524930946| 6.325375406399083|\n",
      "|2017-07-03|94668.76243252479| 18.25461707200767| 78.17694325226547| 20.35557791635185|17.195223293020778|\n",
      "|2017-07-04|95313.96683276288| 22.32803235375923|  50.4074079911003| 8.984114511906204| 6.868896334621589|\n",
      "|2017-07-05|95440.82530922632|23.534423652694652|44.841247660928104|10.412705222705204| 7.964031059031034|\n",
      "|2017-07-06|95312.02019876736|25.778363851992424| 42.49701185958226| 10.85810864999049| 8.447780535930221|\n",
      "|2017-07-07|95248.96706425186|27.469182004089852|40.482749797878675| 9.614079073024804| 7.430200547526521|\n",
      "|2017-07-08|95059.96317789162|  25.7144688644688| 51.47889969005336| 12.10184730986929| 9.885236809576535|\n",
      "|2017-07-09|95089.78527820377|27.075451422027033| 49.46747614048477|12.441132935466957|10.319859653725107|\n",
      "|2017-07-10| 95128.1010232264|28.758966410703227|44.910974230932034|14.278580865387667|12.425794746989531|\n",
      "|2017-07-11|95059.89666140139|30.580405242122854| 41.59478715493988|16.458481004748865|13.907630592351836|\n",
      "|2017-07-12|94791.26359009359| 30.41663144117502| 36.67443695768059|14.077904752827688|10.800456856017346|\n",
      "|2017-07-13| 94660.5128211271|28.239342143762816|  40.2070233102511| 11.50965046888325| 8.878007956805918|\n",
      "|2017-07-14|94698.49576498086|25.985152705061278| 35.94933100639909| 5.461827450735781|  3.10989585931652|\n",
      "|2017-07-15|94722.05143758388|23.879997175673175| 48.98377471286015|10.245437171815821| 7.799760959824183|\n",
      "|2017-07-16|95101.30591753831|17.941519693602615| 71.34576150172559|11.484685678666041|  9.46174505220515|\n",
      "|2017-07-17|95316.44255811958|18.957777725805787| 65.99736470368151| 8.730244358596998|  7.05922492028453|\n",
      "|2017-07-18|95171.17375061983|22.368150564730172| 55.49259010934609|11.758467153284702| 9.619662928016169|\n",
      "|2017-07-19|94549.30462410931|24.076660417047684| 47.53020578013586|10.757269963337261| 8.447159080747532|\n",
      "|2017-07-20|94961.17755593521| 25.72600174937875| 43.76265629315902|10.377995553018224| 8.262260148432995|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|    avg(temperature)|    avg(humidity)|           avg(P1)|           avg(P2)|\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "|2019-01-02|94277.97483488954|  0.2862223446972687| 74.5990241713256|19.222103575706054|10.950770719523554|\n",
      "|2019-01-03|94185.75414097095| -0.9239840297377284|78.54737296069372| 16.57162133264632| 9.939423593443362|\n",
      "|2019-01-04|94675.80338418219|  -3.386999603074322|77.83840876123026| 21.65103065346319|11.949863957525666|\n",
      "|2019-01-05|94140.74895954347|  -5.785200324751175|73.17563204251462| 38.00989406294358|18.407682986886755|\n",
      "|2019-01-06|93866.05984364073|  -3.111578597616849|74.83235517873523| 23.50780140981135|12.272407056213794|\n",
      "|2019-01-07|94478.34239339548|   -5.15961900245917|73.87984341056178| 16.07664705041001| 8.934470667565789|\n",
      "|2019-01-08|94310.40126971171|  -5.284967437176732|64.82371845579969|43.897234399788395|  20.8284559971851|\n",
      "|2019-01-09|93316.00278393886|  -3.019772111476693|78.67115506372834| 47.66711852108832|23.819357181383506|\n",
      "|2019-01-10| 93102.0068304158|   -1.12067617490115| 86.7210590887459| 80.49611467638873|41.513757763598825|\n",
      "|2019-01-11|94297.55237233473|  -2.223018025987316|76.56800279137443|24.388417236072463|13.660077993228596|\n",
      "|2019-01-12|94341.47538296404|  -2.493073332100738|70.47492749986813|20.042303325273163|10.723956215213859|\n",
      "|2019-01-13|93605.65911501243| -0.0877757009345847|73.31921152012266| 57.62694244069478|29.360505479997684|\n",
      "|2019-01-14|92631.86737526873|-0.37342613312126377|76.55751716753497| 50.78942436212546|26.242853903620592|\n",
      "|2019-01-15|93587.95309522722| -1.8121388928515512|61.58520348896456| 9.767134468659089| 4.825930595195214|\n",
      "|2019-01-16|93976.78595135934|   2.043889381055683|56.09658440117973|16.884932248267503| 8.203928237676196|\n",
      "|2019-01-17|94250.34083361164|  1.2182875318400386|65.71913940022587|102.31605196377613| 51.65690033448024|\n",
      "|2019-01-18|94109.45809807378|  0.7619539844628659|68.80602901853857|163.85611665435837| 84.29717199236241|\n",
      "|2019-01-19|94331.25944607279|   3.057684423725045|77.34454533549827|128.98002930068998| 71.16563729001369|\n",
      "|2019-01-20|94326.31132735757|    4.24321125725902|85.90690039073569| 58.60297220519491|31.748320877928982|\n",
      "|2019-01-21|94397.92855471486|   3.234468095565855|87.60826015141049| 67.97363972290637|35.336565828059626|\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df = df_bme_transformed.join(df_sds_transformed, on=['ts'], how='left').orderBy([\"ts\"], ascending=True)\n",
    "combined_df.show()\n",
    "x_train = combined_df.filter(F.col('ts').between(\"2017-07-01\", \"2019-01-01\"))\n",
    "#x_test = combined_df.filter(F.col('ts').between(\"2018-10-02\", \"2019-05-01\"))\n",
    "x_test = combined_df.filter(F.col('ts') > \"2019-01-01\")\n",
    "x_train = x_train.where(col(\"avg(P1)\").isNotNull())\n",
    "x_test = x_test.where(col(\"avg(P1)\").isNotNull())\n",
    "# x_train.show(x_train.count(), False)\n",
    "# x_test.show(x_test.count(), False)\n",
    "x_train.show()\n",
    "x_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ElasticNetParam: 0.5\n",
      "  RegParam: 0.5\n",
      "13.373296421326268\n",
      "-0.6713492547504689\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['avg(pressure)', 'avg(temperature)', 'avg(humidity)'], outputCol = 'features')\n",
    "features_df = vectorAssembler.transform(combined_df)\n",
    "features_df = features_df.select(['features', 'avg(P2)'])\n",
    "test_features_df = vectorAssembler.transform(x_test)\n",
    "train_features_df = vectorAssembler.transform(x_train)\n",
    "test_features_df = test_features_df.withColumnRenamed(\"avg(P2)\",\"label\")\n",
    "train_features_df = train_features_df.withColumnRenamed(\"avg(P2)\",\"label\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(lr.regParam, [0.1, 0.3, 0.5]) \\\n",
    "            .addGrid(lr.elasticNetParam, [.5, .7, .9]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "cvModel = cv.fit(train_features_df)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  ElasticNetParam:\", besty._java_obj.parent().getElasticNetParam())\n",
    "print(\"  RegParam:\", besty._java_obj.parent().getRegParam())\n",
    "test_predictions = besty.transform(test_features_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"r2\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "r2 = evaluator.evaluate(test_predictions)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  family: gaussian\n",
      "  RegParam: 0.5\n",
      "13.628717015104831\n",
      "-0.7358021349522113\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "glr = GeneralizedLinearRegression(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(glr.family, ['gaussian', 'Gamma'])\\\n",
    "            .addGrid(glr.regParam, [0.1, 0.3, 0.5]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=glr, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(train_features_df)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  family:\", besty._java_obj.parent().getFamily())\n",
    "print(\"  RegParam:\", besty._java_obj.parent().getRegParam())\n",
    "test_predictions = besty.transform(test_features_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"r2\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "r2 = evaluator.evaluate(test_predictions)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.597106349168207\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import FMRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "featureScaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\").fit(train_features_df)\n",
    "fm = FMRegressor(featuresCol=\"scaledFeatures\", stepSize=0.9)\n",
    "pipeline = Pipeline(stages=[featureScaler, fm])\n",
    "model = pipeline.fit(train_features_df)\n",
    "test_predictions = model.transform(test_features_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.62787164726288\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import IsotonicRegression\n",
    "\n",
    "IR = IsotonicRegression()\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=IR, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(train_features_df)\n",
    "besty = cvModel.bestModel\n",
    "test_predictions = besty.transform(test_features_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max depth: 5\n",
      "  max bins: 16\n",
      "16.878079695058698\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(gbt.maxDepth, [5, 10, 15]) \\\n",
    "            .addGrid(gbt.maxBins, [16]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(train_features_df)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  max depth:\", besty._java_obj.parent().getMaxDepth())\n",
    "print(\"  max bins:\", besty._java_obj.parent().getMaxBins())\n",
    "test_predictions = besty.transform(test_features_df)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Function Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|  avg(temperature)|     avg(humidity)|           avg(P2)|      prev_avg(P2)|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|2017-07-01|94572.18985080464| 33.33327613327619|32.792403355736745| 8.341274009698298|              null|\n",
      "|2017-07-02|94441.42854684066|28.197254514672572| 44.52180304740427| 6.325375406399083| 8.341274009698298|\n",
      "|2017-07-03|94668.76243252479| 18.25461707200767| 78.17694325226547|17.195223293020778| 6.325375406399083|\n",
      "|2017-07-04|95313.96683276288| 22.32803235375923|  50.4074079911003| 6.868896334621589|17.195223293020778|\n",
      "|2017-07-05|95440.82530922632|23.534423652694652|44.841247660928104| 7.964031059031034| 6.868896334621589|\n",
      "|2017-07-06|95312.02019876736|25.778363851992424| 42.49701185958226| 8.447780535930221| 7.964031059031034|\n",
      "|2017-07-07|95248.96706425186|27.469182004089852|40.482749797878675| 7.430200547526521| 8.447780535930221|\n",
      "|2017-07-08|95059.96317789162|  25.7144688644688| 51.47889969005336| 9.885236809576535| 7.430200547526521|\n",
      "|2017-07-09|95089.78527820377|27.075451422027033| 49.46747614048477|10.319859653725107| 9.885236809576535|\n",
      "|2017-07-10| 95128.1010232264|28.758966410703227|44.910974230932034|12.425794746989531|10.319859653725107|\n",
      "|2017-07-11|95059.89666140139|30.580405242122854| 41.59478715493988|13.907630592351836|12.425794746989531|\n",
      "|2017-07-12|94791.26359009359| 30.41663144117502| 36.67443695768059|10.800456856017346|13.907630592351836|\n",
      "|2017-07-13| 94660.5128211271|28.239342143762816|  40.2070233102511| 8.878007956805918|10.800456856017346|\n",
      "|2017-07-14|94698.49576498086|25.985152705061278| 35.94933100639909|  3.10989585931652| 8.878007956805918|\n",
      "|2017-07-15|94722.05143758388|23.879997175673175| 48.98377471286015| 7.799760959824183|  3.10989585931652|\n",
      "|2017-07-16|95101.30591753831|17.941519693602615| 71.34576150172559|  9.46174505220515| 7.799760959824183|\n",
      "|2017-07-17|95316.44255811958|18.957777725805787| 65.99736470368151|  7.05922492028453|  9.46174505220515|\n",
      "|2017-07-18|95171.17375061983|22.368150564730172| 55.49259010934609| 9.619662928016169|  7.05922492028453|\n",
      "|2017-07-19|94549.30462410931|24.076660417047684| 47.53020578013586| 8.447159080747532| 9.619662928016169|\n",
      "|2017-07-20|94961.17755593521| 25.72600174937875| 43.76265629315902| 8.262260148432995| 8.447159080747532|\n",
      "+----------+-----------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "|        ts|    avg(pressure)|    avg(temperature)|    avg(humidity)|           avg(P2)|      prev_avg(P2)|\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "|2019-01-02|94277.97483488954|  0.2862223446972687| 74.5990241713256|10.950770719523554|              null|\n",
      "|2019-01-03|94185.75414097095| -0.9239840297377284|78.54737296069372| 9.939423593443362|10.950770719523554|\n",
      "|2019-01-04|94675.80338418219|  -3.386999603074322|77.83840876123026|11.949863957525666| 9.939423593443362|\n",
      "|2019-01-05|94140.74895954347|  -5.785200324751175|73.17563204251462|18.407682986886755|11.949863957525666|\n",
      "|2019-01-06|93866.05984364073|  -3.111578597616849|74.83235517873523|12.272407056213794|18.407682986886755|\n",
      "|2019-01-07|94478.34239339548|   -5.15961900245917|73.87984341056178| 8.934470667565789|12.272407056213794|\n",
      "|2019-01-08|94310.40126971171|  -5.284967437176732|64.82371845579969|  20.8284559971851| 8.934470667565789|\n",
      "|2019-01-09|93316.00278393886|  -3.019772111476693|78.67115506372834|23.819357181383506|  20.8284559971851|\n",
      "|2019-01-10| 93102.0068304158|   -1.12067617490115| 86.7210590887459|41.513757763598825|23.819357181383506|\n",
      "|2019-01-11|94297.55237233473|  -2.223018025987316|76.56800279137443|13.660077993228596|41.513757763598825|\n",
      "|2019-01-12|94341.47538296404|  -2.493073332100738|70.47492749986813|10.723956215213859|13.660077993228596|\n",
      "|2019-01-13|93605.65911501243| -0.0877757009345847|73.31921152012266|29.360505479997684|10.723956215213859|\n",
      "|2019-01-14|92631.86737526873|-0.37342613312126377|76.55751716753497|26.242853903620592|29.360505479997684|\n",
      "|2019-01-15|93587.95309522722| -1.8121388928515512|61.58520348896456| 4.825930595195214|26.242853903620592|\n",
      "|2019-01-16|93976.78595135934|   2.043889381055683|56.09658440117973| 8.203928237676196| 4.825930595195214|\n",
      "|2019-01-17|94250.34083361164|  1.2182875318400386|65.71913940022587| 51.65690033448024| 8.203928237676196|\n",
      "|2019-01-18|94109.45809807378|  0.7619539844628659|68.80602901853857| 84.29717199236241| 51.65690033448024|\n",
      "|2019-01-19|94331.25944607279|   3.057684423725045|77.34454533549827| 71.16563729001369| 84.29717199236241|\n",
      "|2019-01-20|94326.31132735757|    4.24321125725902|85.90690039073569|31.748320877928982| 71.16563729001369|\n",
      "|2019-01-21|94397.92855471486|   3.234468095565855|87.60826015141049|35.336565828059626|31.748320877928982|\n",
      "+----------+-----------------+--------------------+-----------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "w = Window.orderBy(\"ts\")\n",
    "df1_train = x_train.withColumn(\"prev_avg(P2)\", F.lag(\"avg(P2)\").over(w))\n",
    "df1_train.drop(\"avg(P1)\").show()\n",
    "df1_test = x_test.withColumn(\"prev_avg(P2)\", F.lag(\"avg(P2)\").over(w))\n",
    "df1_test.drop(\"avg(P1)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|        ts|           avg(P2)|\n",
      "+----------+------------------+\n",
      "|2017-07-01| 8.341274009698298|\n",
      "|2017-07-02| 6.325375406399083|\n",
      "|2017-07-03|17.195223293020778|\n",
      "|2017-07-04| 6.868896334621589|\n",
      "|2017-07-05| 7.964031059031034|\n",
      "|2017-07-06| 8.447780535930221|\n",
      "|2017-07-07| 7.430200547526521|\n",
      "|2017-07-08| 9.885236809576535|\n",
      "|2017-07-09|10.319859653725107|\n",
      "|2017-07-10|12.425794746989531|\n",
      "|2017-07-11|13.907630592351836|\n",
      "|2017-07-12|10.800456856017346|\n",
      "|2017-07-13| 8.878007956805918|\n",
      "|2017-07-14|  3.10989585931652|\n",
      "|2017-07-15| 7.799760959824183|\n",
      "|2017-07-16|  9.46174505220515|\n",
      "|2017-07-17|  7.05922492028453|\n",
      "|2017-07-18| 9.619662928016169|\n",
      "|2017-07-19| 8.447159080747532|\n",
      "|2017-07-20| 8.262260148432995|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lags_train = x_train.select(\"ts\", \"avg(P2)\")\n",
    "df_lags_test = x_test.select(\"ts\", \"avg(P2)\")\n",
    "df_lags_train.show()\n",
    "for i in range(1, 8): \n",
    "    df_lags_train = df_lags_train.withColumn(\"P1_lag_\"+str(i), F.lag(F.col('avg(P2)'), i).over(w))\n",
    "    \n",
    "    df_lags_test = df_lags_test.withColumn(\"P1_lag_\"+str(i), F.lag(F.col('avg(P2)'), i).over(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_feature_df_train = df_lags_train.select(\"P1_lag_1\", \"P1_lag_2\", \"P1_lag_3\", \"P1_lag_4\", \"P1_lag_5\", \"P1_lag_6\", \"P1_lag_7\", \"avg(P2)\") \n",
    "lag_feature_df_train = lag_feature_df_train.where(col(\"P1_lag_7\").isNotNull()) \n",
    "lag_feature_df_test = df_lags_test.select(\"P1_lag_1\", \"P1_lag_2\", \"P1_lag_3\", \"P1_lag_4\", \"P1_lag_5\", \"P1_lag_6\", \"P1_lag_7\",\"avg(P2)\") \n",
    "lag_feature_df_test = lag_feature_df_test.where(col(\"P1_lag_7\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagging P1 values from the past 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ElasticNetParam: 0.9\n",
      "  RegParam: 0.5\n",
      "5.37711055703234\n",
      "0.06921662035409137\n"
     ]
    }
   ],
   "source": [
    "# vectorAssembler = VectorAssembler(inputCols = [\"P1_lag_1\", \"P1_lag_2\", \"P1_lag_3\", \"P1_lag_4\", \"P1_lag_5\", \"P1_lag_6\", \"P1_lag_7\",\"P1_lag_8\", \"P1_lag_9\", \"P1_lag_10\", \"P1_lag_11\", \"P1_lag_12\", \"P1_lag_13\", \"P1_lag_14\"], outputCol = 'features')\n",
    "vectorAssembler = VectorAssembler(inputCols = [\"P1_lag_1\", \"P1_lag_2\", \"P1_lag_3\", \"P1_lag_4\", \"P1_lag_5\", \"P1_lag_6\", \"P1_lag_7\"], outputCol = 'features')\n",
    "lag_df_train = vectorAssembler.transform(lag_feature_df_train)\n",
    "lag_df_train = lag_df_train.select(['features', 'avg(P2)'])\n",
    "lag_df_test = vectorAssembler.transform(lag_feature_df_test)\n",
    "lag_df_test = lag_df_test.select(['features', 'avg(P2)'])\n",
    "\n",
    "lag_df_test = lag_df_test.withColumnRenamed(\"avg(P2)\",\"label\")\n",
    "lag_df_train = lag_df_train.withColumnRenamed(\"avg(P2)\",\"label\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(lr.regParam, [0.1, 0.3, 0.5]) \\\n",
    "            .addGrid(lr.elasticNetParam, [.5, .7, .9]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(lag_df_train)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  ElasticNetParam:\", besty._java_obj.parent().getElasticNetParam())\n",
    "print(\"  RegParam:\", besty._java_obj.parent().getRegParam())\n",
    "test_predictions = besty.transform(lag_df_test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"r2\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "r2 = evaluator.evaluate(test_predictions)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  family: gaussian\n",
      "  RegParam: 0.5\n",
      "5.709785426738006\n",
      "-0.04951889904381068\n"
     ]
    }
   ],
   "source": [
    "glr = GeneralizedLinearRegression(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(glr.family, ['gaussian', 'Gamma'])\\\n",
    "            .addGrid(glr.regParam, [0.1, 0.3, 0.5]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=glr, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(lag_df_train)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  family:\", besty._java_obj.parent().getFamily())\n",
    "print(\"  RegParam:\", besty._java_obj.parent().getRegParam())\n",
    "test_predictions = besty.transform(lag_df_test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"r2\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "r2 = evaluator.evaluate(test_predictions)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max depth: 5\n",
      "  max bins: 16\n",
      "12.839929143771244\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol = 'features', labelCol='label', maxIter=50)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(gbt.maxDepth, [5, 10, 15]) \\\n",
    "            .addGrid(gbt.maxBins, [16]) \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(lag_df_train)\n",
    "besty = cvModel.bestModel\n",
    "print(\"  max depth:\", besty._java_obj.parent().getMaxDepth())\n",
    "print(\"  max bins:\", besty._java_obj.parent().getMaxBins())\n",
    "test_predictions = besty.transform(lag_df_test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.751204596565843\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import IsotonicRegression\n",
    "IR = IsotonicRegression()\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .build()\n",
    "cv = CrossValidator(estimator=IR, estimatorParamMaps=param_grid, evaluator=RegressionEvaluator(), numFolds=5).setParallelism(8)\n",
    "\n",
    "cvModel = cv.fit(lag_df_train)\n",
    "besty = cvModel.bestModel\n",
    "test_predictions = besty.transform(lag_df_test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\")\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagging P1 values from past  7 days AND lagging temps / pressures / humidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zoo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cdeffd01c5d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mzoo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'zoo' is not defined"
     ]
    }
   ],
   "source": [
    "zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert them into long rows with the lag information next...\n",
    "         # groupBy sensor?\n",
    "         # get averages for each day for each sensor\n",
    "         # take the past 7 days lag information for variables\n",
    "         # https://www.slideshare.net/SparkSummit/time-series-analytics-with-spark-spark-summit-east-talk-by-simon-ouellette\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@sergey.ivanchuk/practical-pyspark-window-function-examples-cb5c7e1a3c41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
